{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "819b7610-0d65-4fdd-b962-28ba2dc3937e",
   "metadata": {},
   "source": [
    "# Spark and MongoDB Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6533f714-5637-4c21-8b84-d99a56b3bea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2323k  100 2323k    0     0  20.5M      0 --:--:-- --:--:-- --:--:-- 20.6M\n"
     ]
    }
   ],
   "source": [
    "mongo_jarname = 'mongo-spark-connector_2.13-10.1.1-all.jar'\n",
    "mongo_package_name = 'org.mongodb.spark:mongo-spark-connector_2.12:3.0.1'\n",
    "\n",
    "# download the spark mongo connector\n",
    "!curl -o mongo-spark-connector_2.13-10.1.1-all.jar \"https://repo1.maven.org/maven2/org/mongodb/spark/mongo-spark-connector_2.13/10.1.1/mongo-spark-connector_2.13-10.1.1-all.jar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1ed6c35-6f2c-4e9b-b3c7-b052a84500dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Data Engineering_Indi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/Data Engineering_Indi/mongo-spark-connector_2.13-10.1.1-all.jar'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "mongo_jar_location = current_dir + \"/\" + mongo_jarname\n",
    "mongo_jar_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a87bf33-d8af-4d62-b028-0c861b83574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.5.4-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f74c5167-7fd7-4b02-b9f4-a508484739f2;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      ":: resolution report :: resolve 475ms :: artifacts dl 45ms\n",
      "\t:: modules in use:\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   4   |   0   |   0   |   0   ||   4   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f74c5167-7fd7-4b02-b9f4-a508484739f2\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 4 already retrieved (0kB/8ms)\n",
      "25/04/01 19:26:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Unified_Spark_Session\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n",
    "    .config(\"spark.mongodb.read.connection.uri\", \"mongodb://localhost:27017/project_db.reddit_posts\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d063d1c0-ad3c-4d2c-8184-09dce3ea661d",
   "metadata": {},
   "source": [
    "# Reddit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0cfffa-9dcd-4f61-a23f-f96897cd014c",
   "metadata": {},
   "source": [
    "## 1.  Load Data to MongoDB and Creating Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dca4618-35e0-494f-9c6b-6400bedee0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"localhost\", 27017)\n",
    "db = client[\"project_db\"]\n",
    "\n",
    "# Load Reddit data\n",
    "reddit_api_data = pd.read_csv(\"reddit_api_data.csv\")\n",
    "db[\"reddit_api_data\"].insert_many(reddit_api_data.to_dict(orient=\"records\"))\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cfddadc-3758-4664-b955-b321a943dac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to local MongoDB\n",
    "client = MongoClient(\"localhost\", 27017)\n",
    "db = client[\"project_db\"]\n",
    "\n",
    "# Load raddit data\n",
    "data_raddit = list(db[\"reddit_api_data\"].find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cadba6e-0c12-4e37-b64f-9c9329cbec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean JSON and Load into SparkÂ¶\n",
    "#define a cleaning function (Reusable for Both)\n",
    "\n",
    "def clean_records(data_json):\n",
    "    for record in data_json:\n",
    "        record.pop(\"_id\", None)\n",
    "\n",
    "        # Clean num_comments\n",
    "        if isinstance(record.get(\"num_comments\"), dict):\n",
    "            record[\"num_comments\"] = record[\"num_comments\"].get(\"$numberDouble\", \"0\")\n",
    "        try:\n",
    "            record[\"num_comments\"] = int(float(record[\"num_comments\"]))\n",
    "        except:\n",
    "            record[\"num_comments\"] = 0\n",
    "\n",
    "        # Clean score\n",
    "        try:\n",
    "            record[\"score\"] = int(record.get(\"score\", 0))\n",
    "        except:\n",
    "            record[\"score\"] = 0\n",
    "\n",
    "        # Clean sentiment fields\n",
    "        for field in [\"sentiment_neg\", \"sentiment_pos\", \"sentiment_compound\"]:\n",
    "            val = record.get(field, 0.0)\n",
    "            if isinstance(val, dict):\n",
    "                val = val.get(\"$numberDouble\", \"0.0\")\n",
    "            try:\n",
    "                record[field] = float(val)\n",
    "            except:\n",
    "                record[field] = 0.0\n",
    "    return data_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30eae4f6-cafa-40cd-b756-ed4200cead96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning function\n",
    "data_reddit_cleaned = clean_records(data_raddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9c8deb9-3843-4c88-a7f0-02b9b4e7f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema and load into Spark\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"post_or_comment\", StringType(), True),\n",
    "    StructField(\"product_label\", StringType(), True),\n",
    "    StructField(\"content\", StringType(), True),\n",
    "    StructField(\"score\", IntegerType(), True),\n",
    "    StructField(\"num_comments\", IntegerType(), True),\n",
    "    StructField(\"created_date\", StringType(), True),\n",
    "    StructField(\"sentiment_neg\", DoubleType(), True),\n",
    "    StructField(\"sentiment_pos\", DoubleType(), True),\n",
    "    StructField(\"sentiment_compound\", DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6afaa3f9-f6d5-44e4-a6d4-89bb01ae5842",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reddit_df = spark.createDataFrame(data_reddit_cleaned, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0645af01-82e4-4e97-8c85-4f0d4cdf7428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/01 19:26:17 WARN TaskSetManager: Stage 0 contains a task of very large size (17171 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/04/01 19:26:22 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 0 (TID 0): Attempting to kill Python Worker\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------+--------------------+-----+------------+------------+-------------+-------------+------------------+\n",
      "|post_or_comment|   product_label|             content|score|num_comments|created_date|sentiment_neg|sentiment_pos|sentiment_compound|\n",
      "+---------------+----------------+--------------------+-----+------------+------------+-------------+-------------+------------------+\n",
      "|           Post|Tesla Cybertruck|Does anyone like ...|   94|         646|  2024-10-14|          0.0|        0.385|            0.3612|\n",
      "|        Comment|Tesla Cybertruck|I appreciate the ...|  305|           0|  2024-10-14|        0.099|        0.131|            0.2516|\n",
      "|        Comment|Tesla Cybertruck|My 3 year old doe...|  122|           0|  2024-10-14|          0.0|          0.0|               0.0|\n",
      "|        Comment|Tesla Cybertruck|I had a 2 door st...|    9|           0|  2024-10-14|          0.0|        0.026|            0.2023|\n",
      "|        Comment|Tesla Cybertruck|I actually really...|    9|           0|  2024-10-14|          0.0|        0.098|            0.3612|\n",
      "+---------------+----------------+--------------------+-----+------------+------------+-------------+-------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_reddit_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e4a0e-3e9a-42bc-ba98-4053fb8b601f",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91700a64-614a-4637-a2ca-72f3ab785d3a",
   "metadata": {},
   "source": [
    "### Data Cleaning Process\n",
    "1. Drop unnecessary columns to merge with Youtube data\n",
    "2. Add source to the data\n",
    "3. Drop nulls\n",
    "4. Trim whitespace\n",
    "5. Convert string to data type\n",
    "6. Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24851ba4-ee16-4d9d-af18-aa6ee9c09d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/01 19:26:25 WARN TaskSetManager: Stage 1 contains a task of very large size (17171 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 1:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------+\n",
      "|product_label   |content                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |created_date|source|\n",
      "+----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------+\n",
      "|Tesla Cybertruck|Does anyone like the cybertruck?                                                                                                                                                                                                                                                                                                                                                                                                                                                               |2024-10-14  |reddit|\n",
      "|Tesla Cybertruck|I appreciate the willingness to take risks when every vehicle today is either an F-150, Suburban, or Rav4. We need some new design concepts out there.\\n\\nThat said, the triangle profile makes it unusable as a truck (same problem as the old Honda Ridgelines and Avalanches), and simultaneously less useful than a large SUV. If Tesla had released a truck/van platform focused on utility instead of design they would have killed Rivian and could make huge strides in fleet vehicles.|2024-10-14  |reddit|\n",
      "|Tesla Cybertruck|My 3 year old does. Calls it out every time he sees one. Unlikely I will get one. Price and how big it is. All I go is Costco and office it would be practical.                                                                                                                                                                                                                                                                                                                                |2024-10-14  |reddit|\n",
      "|Tesla Cybertruck|I had a 2 door standard cab 2000 Ranger (gas). I'd take an electric version above the CT and day of the week. Why? It had a 6' bed that could actually hold long lumber. As long as the Ranger EV could tow, I'd be fine. EV work trucks that aren't 4D cars with an open trunk seemingly don't exist yet, and those are hideously expensive, gas or electric.                                                                                                                                 |2024-10-14  |reddit|\n",
      "|Tesla Cybertruck|I actually reallyyy like it when it has a matte black wrap (or most wraps really). The bare stainless steel looks a little unfinished                                                                                                                                                                                                                                                                                                                                                          |2024-10-14  |reddit|\n",
      "+----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/01 19:26:29 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 1 (TID 1): Attempting to kill Python Worker\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Step 1: Drop unnecessary columns\n",
    "reddit_clean_df = data_reddit_df.drop(\n",
    "    \"post_or_comment\", \n",
    "    \"score\", \n",
    "    \"num_comments\", \n",
    "    \"sentiment_neg\", \n",
    "    \"sentiment_pos\", \n",
    "    \"sentiment_compound\"\n",
    ")\n",
    "\n",
    "# Step 2: Add 'source' column with value 'reddit'\n",
    "reddit_clean_df = reddit_clean_df.withColumn(\"source\", lit(\"reddit\"))\n",
    "\n",
    "# Preview cleaned DataFrame\n",
    "reddit_clean_df.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f961c65a-1c61-4172-b2f3-6edb68858add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/01 19:26:30 WARN TaskSetManager: Stage 2 contains a task of very large size (17171 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 2:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------+\n",
      "|product_label     |content                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |created_date|source|\n",
      "+------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------+\n",
      "|Tesla Cybertruck  |\\n#[r/cybertruck](https://www.reddit.com/r/cybertruck/) is now private. If you are unable to find it, here is a link to it.\\n\\nAs we are not a support sub, please make sure to use the proper resources if you have questions: [Official Tesla Support](https://www.tesla.com/support), [r/TeslaSupport](https://www.reddit.com/r/TeslaSupport/) | [r/TeslaLounge](https://www.reddit.com/r/TeslaLounge/) personal content | [Discord Live Chat](https://discord.gg/tesla) for anything.\\n\\n\\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/teslamotors) if you have any questions or concerns.*|2025-01-13  |reddit|\n",
      "|Tesla Cybertruck  |\\n#[r/cybertruck](https://www.reddit.com/r/cybertruck/) is now private. If you are unable to find it, here is a link to it.\\n\\nAs we are not a support sub, please make sure to use the proper resources if you have questions: [Official Tesla Support](https://www.tesla.com/support), [r/TeslaSupport](https://www.reddit.com/r/TeslaSupport/) | [r/TeslaLounge](https://www.reddit.com/r/TeslaLounge/) personal content | [Discord Live Chat](https://discord.gg/tesla) for anything.\\n\\n\\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/teslamotors) if you have any questions or concerns.*|2025-01-15  |reddit|\n",
      "|Chevy Silverado EV|![gif](emote|free_emotes_pack|facepalm)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |2024-07-04  |reddit|\n",
      "|Chevy Silverado EV|![gif](emote|free_emotes_pack|thumbs_down)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |2024-08-25  |reddit|\n",
      "|Rivian R1T        |![gif](giphy|3o84sw9CmwYpAnRRni)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |2024-03-02  |reddit|\n",
      "+------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, trim, length, to_date\n",
    "\n",
    "# Step 3: Drop rows with nulls in important fields\n",
    "reddit_clean_df = reddit_clean_df.dropna(subset=[\"content\", \"product_label\"])\n",
    "\n",
    "# Step 4: Trim whitespace from strings\n",
    "reddit_clean_df = reddit_clean_df.withColumn(\"content\", trim(col(\"content\")))\n",
    "reddit_clean_df = reddit_clean_df.withColumn(\"product_label\", trim(col(\"product_label\")))\n",
    "\n",
    "# Step 5: Convert string date to DateType\n",
    "reddit_clean_df = reddit_clean_df.withColumn(\"created_date\", to_date(col(\"created_date\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Step 6: Drop duplicates (based on content and date)\n",
    "reddit_clean_df = reddit_clean_df.dropDuplicates(subset=[\"content\", \"created_date\"])\n",
    "\n",
    "# View cleaned data\n",
    "reddit_clean_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4db5c240-68c6-4ae6-9264-a3c8beee88f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/01 19:26:35 WARN TaskSetManager: Stage 5 contains a task of very large size (17171 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 5:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             content|\n",
      "+--------------------+\n",
      "|If only they give...|\n",
      "|Tesla sales are p...|\n",
      "|   Tesla Chumpmobile|\n",
      "|Q1 deliveries are...|\n",
      "|Wouldn't get one ...|\n",
      "|Just trying to of...|\n",
      "|Oh, I see it now....|\n",
      "|It's weird that w...|\n",
      "|They have terribl...|\n",
      "|It's not a good t...|\n",
      "|Because it was a ...|\n",
      "|They've been musked!|\n",
      "|I put a deposit d...|\n",
      "|Richard Branson w...|\n",
      "|The lightning doe...|\n",
      "|Seen a ton of the...|\n",
      "|What a fugly car....|\n",
      "|The next issue is...|\n",
      "|The broken glass ...|\n",
      "|Iâ€™ve seen a singl...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "reddit_clean_df.select(\"content\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdd0ec6-c659-433f-b1e4-984440aebb54",
   "metadata": {},
   "source": [
    "# Youtube Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf3c7fc-ecb0-4682-bdcf-b05f14c70d06",
   "metadata": {},
   "source": [
    "## 1.  Load Data to MongoDB and Creating Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3128a395-21dd-487d-b739-e907f3771653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New YouTube Comments inserted: 4793\n"
     ]
    }
   ],
   "source": [
    "# Load from MongoDB \n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Load the correct final CSV\n",
    "youtube_api_df = pd.read_csv(\"youtube_api_data.csv\")\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"localhost\", 27017)\n",
    "db = client[\"project_db\"]\n",
    "\n",
    "# Insert data\n",
    "db[\"youtube_data\"].insert_many(youtube_api_df.to_dict(orient=\"records\"))\n",
    "\n",
    "# Confirm insertion count\n",
    "print(\"New YouTube Comments inserted:\", db[\"youtube_comments\"].count_documents({}))\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36506d76-f3ac-4d7b-a252-b8f7cb30eac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('67ec2a51408604f2c9d96716'), 'Product': 'Tesla Cybertruck', 'Review Text': 'Screw the truck, I never been through neighborhoods like that ðŸ˜‚', 'Review Date': '2025-03-29T20:03:24Z', 'source': 'YouTube', 'features': 'none', 'like_count': 0}\n"
     ]
    }
   ],
   "source": [
    "# Connect to MongoDB\n",
    "client = MongoClient(\"localhost\", 27017)\n",
    "db = client[\"project_db\"]\n",
    "\n",
    "print(db[\"youtube_data\"].find_one())\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73278b9a-b3de-44c2-95d7-12bf3a543576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/01 19:26:37 WARN TaskSetManager: Stage 8 contains a task of very large size (2517 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+-------+--------+----------+\n",
      "|Product         |Review Text                                                                                                                                                                     |Review Date         |source |features|like_count|\n",
      "+----------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+-------+--------+----------+\n",
      "|Tesla Cybertruck|Screw the truck, I never been through neighborhoods like that ðŸ˜‚                                                                                                                |2025-03-29T20:03:24Z|YouTube|none    |0         |\n",
      "|Tesla Cybertruck|Iconic...in the sense that it&#39;s one of the worst cars (if you can call it a car) that I&#39;ve ever seen. Thank god you can&#39;t buy them in my country.                   |2025-03-28T17:35:58Z|YouTube|none    |0         |\n",
      "|Tesla Cybertruck|this is literally a tv episode                                                                                                                                                  |2025-03-27T19:58:54Z|YouTube|none    |0         |\n",
      "|Tesla Cybertruck|that intro monologue actually aged well                                                                                                                                         |2025-03-27T19:55:22Z|YouTube|none    |0         |\n",
      "|Tesla Cybertruck|at this point i have to admit that this is an extremely iconic design, like the coke bottle                                                                                     |2025-03-27T14:37:31Z|YouTube|design  |0         |\n",
      "|Tesla Cybertruck|iconic of being shite                                                                                                                                                           |2025-03-27T05:56:59Z|YouTube|none    |0         |\n",
      "|Tesla Cybertruck|@amitaryal543<br>0 seconds ago<br>â€œMost of the millions of people, who will end up with theseâ€”cybertrucks.â€ Bought for and paid by Tesla. Can someone spell fanboy infomercials?|2025-03-26T17:51:40Z|YouTube|none    |0         |\n",
      "|Tesla Cybertruck|Time to go bald bro ðŸ˜‚ðŸ˜‚ðŸ˜‚                                                                                                                                                      |2025-03-26T17:13:09Z|YouTube|none    |0         |\n",
      "|Tesla Cybertruck|I love this truck! Now I actually have a solid reasonsâ€” other than thinking it looks cool.  Thanks for an excellent review.                                                     |2025-03-25T04:50:13Z|YouTube|design  |0         |\n",
      "|Tesla Cybertruck|saw it in person today, its no bigger than a ford ranger raptor, or a toyota fortuna...                                                                                         |2025-03-25T04:18:50Z|YouTube|none    |0         |\n",
      "+----------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+-------+--------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB and load fresh valid data\n",
    "client = MongoClient(\"localhost\", 27017)\n",
    "db = client[\"project_db\"]\n",
    "youtube_comments_data = list(db[\"youtube_data\"].find())\n",
    "\n",
    "# Keep only valid rows (correct structure)\n",
    "valid_rows = [row for row in youtube_comments_data if 'Product' in row]\n",
    "\n",
    "# Remove MongoDB `_id` field\n",
    "for row in valid_rows:\n",
    "    row.pop('_id', None)\n",
    "\n",
    "# Define schema for Spark\n",
    "youtube_schema = StructType([\n",
    "    StructField(\"Product\", StringType(), True),\n",
    "    StructField(\"Review Text\", StringType(), True),\n",
    "    StructField(\"Review Date\", StringType(), True),\n",
    "    StructField(\"source\", StringType(), True),\n",
    "    StructField(\"features\", StringType(), True),\n",
    "    StructField(\"like_count\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Create Spark DataFrame\n",
    "youtube_data_df = spark.createDataFrame(valid_rows, schema=youtube_schema)\n",
    "\n",
    "# Show final clean result\n",
    "youtube_data_df.show(10, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9af32bd1-fd3c-41ff-bed9-be0f3127b927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/01 19:26:38 WARN TaskSetManager: Stage 9 contains a task of very large size (2517 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "youtube_comments_df shape: (14379, 6)\n"
     ]
    }
   ],
   "source": [
    "df_rows = youtube_data_df.count()\n",
    "df_cols = len(youtube_data_df.columns)\n",
    "print(f\"youtube_comments_df shape: ({df_rows}, {df_cols})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1105de56-cd36-4fd1-84b1-cc4cdfdda817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/01 19:26:39 WARN TaskSetManager: Stage 12 contains a task of very large size (2517 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             Product|\n",
      "+--------------------+\n",
      "|  Chevy Silverado EV|\n",
      "|Ford F-150 Lightning|\n",
      "|       GMC Hummer EV|\n",
      "|          Rivian R1T|\n",
      "|    Tesla Cybertruck|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "youtube_data_df.select(\"Product\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f16913b9-f923-49bf-97df-106cc29eb1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/01 19:26:40 WARN TaskSetManager: Stage 15 contains a task of very large size (2517 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------------------------------------------------------------------------------------------+--------------------+-------+\n",
      "|   product_label|                                                                                             content|        created_date| source|\n",
      "+----------------+----------------------------------------------------------------------------------------------------+--------------------+-------+\n",
      "|Tesla Cybertruck|                                    Screw the truck, I never been through neighborhoods like that ðŸ˜‚|2025-03-29T20:03:24Z|YouTube|\n",
      "|Tesla Cybertruck|Iconic...in the sense that it&#39;s one of the worst cars (if you can call it a car) that I&#39;v...|2025-03-28T17:35:58Z|YouTube|\n",
      "|Tesla Cybertruck|                                                                      this is literally a tv episode|2025-03-27T19:58:54Z|YouTube|\n",
      "|Tesla Cybertruck|                                                             that intro monologue actually aged well|2025-03-27T19:55:22Z|YouTube|\n",
      "|Tesla Cybertruck|         at this point i have to admit that this is an extremely iconic design, like the coke bottle|2025-03-27T14:37:31Z|YouTube|\n",
      "+----------------+----------------------------------------------------------------------------------------------------+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lit, when, concat_ws\n",
    "\n",
    "youtube_clean_df = youtube_data_df \\\n",
    "    .withColumnRenamed(\"Product\", \"product_label\") \\\n",
    "    .withColumn(\"source\", lit(\"YouTube\")) \\\n",
    "    .withColumnRenamed(\"Review Text\", \"content\") \\\n",
    "    .withColumnRenamed(\"Review Date\", \"created_date\") \\\n",
    "    .select(\"product_label\", \"content\", \"created_date\", \"source\")\n",
    "\n",
    "\n",
    "\n",
    "youtube_clean_df.show(5, truncate=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821034d0-3026-49f9-be44-6a21fea313f9",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cfd9b8b-f396-4158-a0fa-9cfe2c9a21e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/01 19:26:40 WARN TaskSetManager: Stage 16 contains a task of very large size (2517 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-------+\n",
      "|product_label   |content                                                                                                                                                      |created_date|source |\n",
      "+----------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-------+\n",
      "|Tesla Cybertruck|Screw the truck, I never been through neighborhoods like that ðŸ˜‚                                                                                             |2025-03-29  |YouTube|\n",
      "|Tesla Cybertruck|Iconic...in the sense that it&#39;s one of the worst cars (if you can call it a car) that I&#39;ve ever seen. Thank god you can&#39;t buy them in my country.|2025-03-28  |YouTube|\n",
      "|Tesla Cybertruck|this is literally a tv episode                                                                                                                               |2025-03-27  |YouTube|\n",
      "|Tesla Cybertruck|that intro monologue actually aged well                                                                                                                      |2025-03-27  |YouTube|\n",
      "|Tesla Cybertruck|at this point i have to admit that this is an extremely iconic design, like the coke bottle                                                                  |2025-03-27  |YouTube|\n",
      "+----------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, to_date, length\n",
    "\n",
    "# Step 1: Keep only rows where 'created_date' is long enough\n",
    "youtube_clean_df = youtube_clean_df.filter(length(col(\"created_date\")) >= 10)\n",
    "\n",
    "# Step 2: Truncate to 'yyyy-MM-dd'\n",
    "youtube_clean_df = youtube_clean_df.withColumn(\"created_date\", col(\"created_date\").substr(1, 10))\n",
    "\n",
    "# Step 3: Convert to DateType safely\n",
    "youtube_clean_df = youtube_clean_df.withColumn(\"created_date\", to_date(col(\"created_date\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Step 4: Show the result\n",
    "youtube_clean_df.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa2fcced-b0a3-47df-84f3-ab81cb712272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/01 19:28:08 WARN TaskSetManager: Stage 20 contains a task of very large size (2517 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 20:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------------------------------------------------------------------------------------------+------------+-------+\n",
      "|     product_label|                                                                                             content|created_date| source|\n",
      "+------------------+----------------------------------------------------------------------------------------------------+------------+-------+\n",
      "|Chevy Silverado EV|                      \"I have a Cyber Truck\"<br>and we're done listening to this guy talk about cars|  2024-11-27|YouTube|\n",
      "|Chevy Silverado EV|\"Like an avalanche or whatever\" Chevrolet invented the midgate, subaru copied and now Chevrolet d...|  2023-09-04|YouTube|\n",
      "|Chevy Silverado EV|   \"Rip gas trucks.\" That fancy toy costs nearly double what the equivalent gas truck does. Wake up.|  2023-08-24|YouTube|\n",
      "|Chevy Silverado EV|                                                               $ Almost 100 grand, nine tons? Yikes!|  2025-02-05|YouTube|\n",
      "|Chevy Silverado EV|                                                                               $100,000 FOR A TRUCK?|  2025-03-09|YouTube|\n",
      "+------------------+----------------------------------------------------------------------------------------------------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, to_date, trim, length, regexp_replace\n",
    "\n",
    "# Step 1: Remove rows with null or short essential fields\n",
    "youtube_clean_df = youtube_clean_df.filter(\n",
    "    (col(\"content\").isNotNull()) &\n",
    "    (col(\"product_label\").isNotNull()) &\n",
    "    (col(\"created_date\").isNotNull()) &\n",
    "    (length(col(\"content\")) > 5)\n",
    ")\n",
    "\n",
    "\n",
    "# Step 2: Trim whitespace\n",
    "youtube_clean_df = youtube_clean_df.withColumn(\"product_label\", trim(col(\"product_label\")))\n",
    "youtube_clean_df = youtube_clean_df.withColumn(\"content\", trim(col(\"content\")))\n",
    "\n",
    "# Step 3: Decode common HTML entities (e.g., &#39; â†’ ')\n",
    "youtube_clean_df = youtube_clean_df.withColumn(\"content\", regexp_replace(\"content\", \"&#39;\", \"'\"))\n",
    "youtube_clean_df = youtube_clean_df.withColumn(\"content\", regexp_replace(\"content\", \"&quot;\", '\"'))\n",
    "youtube_clean_df = youtube_clean_df.withColumn(\"content\", regexp_replace(\"content\", \"&amp;\", \"&\"))\n",
    "\n",
    "# Step 4: Drop duplicate comments (optional)\n",
    "youtube_clean_df = youtube_clean_df.dropDuplicates([\"product_label\", \"content\", \"created_date\"])\n",
    "\n",
    "# âœ… Final Preview\n",
    "youtube_clean_df.show(5, truncate=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0af8f8-79c4-49be-962a-f7570d345add",
   "metadata": {},
   "source": [
    "# Combining Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e6b5178-887c-48d3-925a-3a6ca8cb9c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/01 19:29:49 WARN TaskSetManager: Stage 26 contains a task of very large size (2517 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/04/01 19:29:50 WARN TaskSetManager: Stage 27 contains a task of very large size (17171 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 29:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------------------------------------------------------------------------------------------+------------+-------+\n",
      "|     product_label|                                                                                             content|created_date| source|\n",
      "+------------------+----------------------------------------------------------------------------------------------------+------------+-------+\n",
      "|Chevy Silverado EV|                      \"I have a Cyber Truck\"<br>and we're done listening to this guy talk about cars|  2024-11-27|YouTube|\n",
      "|Chevy Silverado EV|\"Like an avalanche or whatever\" Chevrolet invented the midgate, subaru copied and now Chevrolet d...|  2023-09-04|YouTube|\n",
      "|Chevy Silverado EV|   \"Rip gas trucks.\" That fancy toy costs nearly double what the equivalent gas truck does. Wake up.|  2023-08-24|YouTube|\n",
      "|Chevy Silverado EV|                                                               $ Almost 100 grand, nine tons? Yikes!|  2025-02-05|YouTube|\n",
      "|Chevy Silverado EV|                                                                               $100,000 FOR A TRUCK?|  2025-03-09|YouTube|\n",
      "|Chevy Silverado EV|                                                                                $100,000 ðŸ˜® bullshit|  2024-09-14|YouTube|\n",
      "|Chevy Silverado EV|                                            $100K and no drivers side entrance grab bar. Great idea.|  2024-12-05|YouTube|\n",
      "|Chevy Silverado EV|                                                                $100k newâ€¦ will be patient for used.|  2024-10-19|YouTube|\n",
      "|Chevy Silverado EV|                                                                                  $77k? Haha get out|  2023-07-01|YouTube|\n",
      "|Chevy Silverado EV|                                        $96,000 for 7 years @ 0% interest would be $1142 per month .|  2024-05-26|YouTube|\n",
      "|Chevy Silverado EV|                   $96,000 for a first gen, largely experimental Chevrolet product is mind boggling.|  2024-05-26|YouTube|\n",
      "|Chevy Silverado EV|                                                                 $96,000 for a work truck is insane.|  2024-09-24|YouTube|\n",
      "|Chevy Silverado EV|$96,000. is a lotta dough. But, on par with several competitive offerings from Rivian, Range Rove...|  2025-02-04|YouTube|\n",
      "|Chevy Silverado EV|                                                                     $96K...???????????  We're done!|  2025-02-04|YouTube|\n",
      "|Chevy Silverado EV|                                        $96k and doesn't even have Apple CarPlay. GFY Chevy and GMC!|  2025-03-01|YouTube|\n",
      "|Chevy Silverado EV|      $96k is a non-starter. Absurd to ask that amount for this. EV depreciation will hit this hard.|  2025-02-07|YouTube|\n",
      "|Chevy Silverado EV|                                                                                   $96k is a rip off|  2024-05-31|YouTube|\n",
      "|Chevy Silverado EV|                                                                                         ...massive?|  2025-03-16|YouTube|\n",
      "|Chevy Silverado EV|                                                                 100,000$ lmao who the hell got that|  2024-06-25|YouTube|\n",
      "|Chevy Silverado EV|                                                                                100K lol  no thanks!|  2024-10-02|YouTube|\n",
      "+------------------+----------------------------------------------------------------------------------------------------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Combine all sources: BestBuy, YouTube, Reddit\n",
    "from functools import reduce\n",
    "\n",
    "combined_df = youtube_clean_df.unionByName(reddit_clean_df)\n",
    "\n",
    "# Optional: Preview the final combined dataset\n",
    "combined_df.show(20, truncate=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4119abe4-2df0-41ad-bb80-16aadb2f364b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/01 19:30:16 WARN TaskSetManager: Stage 34 contains a task of very large size (2517 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/04/01 19:30:17 WARN TaskSetManager: Stage 35 contains a task of very large size (17171 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 35:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (15189 rows, 4 columns)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "print(f\"Shape: ({combined_df.count()} rows, {len(combined_df.columns)} columns)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ee5514d-3e5b-48e1-aafd-452593d70c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/01 19:30:50 WARN TaskSetManager: Stage 43 contains a task of very large size (2517 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/04/01 19:30:51 WARN TaskSetManager: Stage 44 contains a task of very large size (17171 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|source |\n",
      "+-------+\n",
      "|YouTube|\n",
      "|reddit |\n",
      "+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/01 19:30:53 WARN TaskSetManager: Stage 56 contains a task of very large size (2517 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/04/01 19:30:54 WARN TaskSetManager: Stage 57 contains a task of very large size (17171 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 57:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|       product_label|\n",
      "+--------------------+\n",
      "|  Chevy Silverado EV|\n",
      "|Ford F-150 Lightning|\n",
      "|       GMC Hummer EV|\n",
      "|          Rivian R1T|\n",
      "|    Tesla Cybertruck|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "combined_df.select(\"source\").distinct().show(truncate=False)\n",
    "combined_df.select(\"product_label\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1687864f-baae-4f2b-9da8-62e8f6473509",
   "metadata": {},
   "source": [
    "# Loading the Cleaned Dataset to PostGres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44534416-e797-456d-8a28-914584da8ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables for your database here for convenience\n",
    "os.environ[\"POSTGRES_HOST\"] = \"uclba-de25v2.cluster-cowglvndjvxv.eu-west-2.rds.amazonaws.com\"\n",
    "os.environ[\"POSTGRES_DB\"] = \"postgres\"\n",
    "os.environ[\"POSTGRES_PASSWORD\"] = \"a7sMkM\"\n",
    "os.environ[\"POSTGRES_USER\"] = \"jaewon.lee.24@ucl.ac.uk\"\n",
    "os.environ[\"POSTGRES_SCHEMA\"] = \"schema_jaewonlee24uclacuk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e86f601-03e4-447b-8e00-9cc0230a31e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uclba-de25v2.cluster-cowglvndjvxv.eu-west-2.rds.amazonaws.com\n",
      "postgres\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"POSTGRES_HOST\"))  # Should print: your_postgres_host\n",
    "print(os.getenv(\"POSTGRES_DB\"))    # Should print: your_database_name\n",
    "# print(os.getenv(\"POSTGRES_PASSWORD\"))    # You Should never print: passwords or sensitive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cea21232-9e2f-474e-926d-ce6f33311ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables for PostgreSQL connection\n",
    "POSTGRES_HOST = os.getenv(\"POSTGRES_HOST\", \"localhost\")\n",
    "POSTGRES_DB = os.getenv(\"POSTGRES_DB\", \"postgres\")\n",
    "POSTGRES_USER = os.getenv(\"POSTGRES_USER\", \"postgres\")\n",
    "POSTGRES_PASSWORD = os.getenv(\"POSTGRES_PASSWORD\", \"postgres\")\n",
    "POSTGRES_PORT = os.getenv(\"POSTGRES_PORT\", 5432) # leave at the default port\n",
    "POSTGRES_SCHEMA = os.getenv(\"POSTGRES_SCHEMA\", \"public\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd663041-675e-4fba-b01b-5519309180a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create PostgreSQL connection string\n",
    "pg_conn_string = f\"postgresql+psycopg2://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}\"\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "pg_engine = create_engine(pg_conn_string, connect_args={\"options\": f\"-c search_path={POSTGRES_SCHEMA}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88e1209d-ad1c-4b0e-92ff-0e020ac517f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/01 19:38:01 WARN TaskSetManager: Stage 65 contains a task of very large size (2517 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/04/01 19:38:02 WARN TaskSetManager: Stage 66 contains a task of very large size (17171 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# saving df as csv\n",
    "\n",
    "# Convert the full final Spark DataFrame to Pandas again\n",
    "combined_pd = combined_df.toPandas()\n",
    "\n",
    "# Export the combined DataFrame to a CSV file\n",
    "combined_pd.to_csv('combined_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abac748d-8d9b-4c5d-9f47-bbf1c14bea83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15189"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the DataFrame to PostgreSQL\n",
    "\n",
    "# Convert the Spark DataFrame to a Pandas DataFrame\n",
    "combined_pd = combined_df.toPandas()\n",
    "\n",
    "\n",
    "combined_pd.to_sql(\n",
    "    name=\"combined_data\",\n",
    "    con=pg_engine,\n",
    "    if_exists=\"replace\",\n",
    "    index=False,\n",
    "    chunksize=1000   # Upload 1000 rows at a time\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c15fa55-5e55-49a6-b68a-7d14a8b87bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15189, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if all row uploaded\n",
    "combined_pd.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b280afb-c720-420c-be01-5899caa3b4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>data_type</th>\n",
       "      <th>character_maximum_length</th>\n",
       "      <th>is_nullable</th>\n",
       "      <th>ordinal_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>product_label</td>\n",
       "      <td>text</td>\n",
       "      <td>None</td>\n",
       "      <td>YES</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content</td>\n",
       "      <td>text</td>\n",
       "      <td>None</td>\n",
       "      <td>YES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>created_date</td>\n",
       "      <td>date</td>\n",
       "      <td>None</td>\n",
       "      <td>YES</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>source</td>\n",
       "      <td>text</td>\n",
       "      <td>None</td>\n",
       "      <td>YES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     column_name data_type character_maximum_length is_nullable  \\\n",
       "0  product_label      text                     None         YES   \n",
       "1        content      text                     None         YES   \n",
       "2   created_date      date                     None         YES   \n",
       "3         source      text                     None         YES   \n",
       "\n",
       "   ordinal_position  \n",
       "0                 1  \n",
       "1                 2  \n",
       "2                 3  \n",
       "3                 4  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verified the upload by querying the PostgreSQL database's system catalog:\n",
    "import pandas as pd\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    column_name,\n",
    "    data_type,\n",
    "    character_maximum_length,\n",
    "    is_nullable,\n",
    "    ordinal_position\n",
    "FROM information_schema.columns\n",
    "WHERE table_name = 'combined_data'\n",
    "  AND table_schema = 'schema_jaewonlee24uclacuk'\n",
    "ORDER BY ordinal_position;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, con=pg_engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68b532a6-60ce-4604-859b-f53e72063b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>example_table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon_reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined_data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       table_name\n",
       "0   example_table\n",
       "1  amazon_reviews\n",
       "2   combined_data"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if the combined_reviews is in my schema\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT table_name \n",
    "FROM information_schema.tables \n",
    "WHERE table_schema = 'schema_jaewonlee24uclacuk';\n",
    "\"\"\"\n",
    "\n",
    "table_list_df = pd.read_sql(query, con=pg_engine)\n",
    "table_list_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7bb512af-6993-4ae1-a6e2-e1a2e52fcecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tesla Cybertruck</td>\n",
       "      <td>5274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ford F-150 Lightning</td>\n",
       "      <td>2955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rivian R1T</td>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GMC Hummer EV</td>\n",
       "      <td>2404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chevy Silverado EV</td>\n",
       "      <td>2070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          product_label  count\n",
       "0      Tesla Cybertruck   5274\n",
       "1  Ford F-150 Lightning   2955\n",
       "2            Rivian R1T   2486\n",
       "3         GMC Hummer EV   2404\n",
       "4    Chevy Silverado EV   2070"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analysis\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \"product_label\", COUNT(*) AS count\n",
    "FROM combined_data\n",
    "GROUP BY \"product_label\"\n",
    "ORDER BY count DESC;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "pd.read_sql(query, con=pg_engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b266ed2-cff9-48a4-a7f3-789c46b1e930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_label</th>\n",
       "      <th>source</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tesla Cybertruck</td>\n",
       "      <td>reddit</td>\n",
       "      <td>4294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ford F-150 Lightning</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rivian R1T</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GMC Hummer EV</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chevy Silverado EV</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GMC Hummer EV</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ford F-150 Lightning</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tesla Cybertruck</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rivian R1T</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chevy Silverado EV</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          product_label   source  review_count\n",
       "0      Tesla Cybertruck   reddit          4294\n",
       "1  Ford F-150 Lightning   reddit          1964\n",
       "2            Rivian R1T   reddit          1595\n",
       "3         GMC Hummer EV   reddit          1413\n",
       "4    Chevy Silverado EV   reddit          1199\n",
       "5         GMC Hummer EV  YouTube           991\n",
       "6  Ford F-150 Lightning  YouTube           991\n",
       "7      Tesla Cybertruck  YouTube           980\n",
       "8            Rivian R1T  YouTube           891\n",
       "9    Chevy Silverado EV  YouTube           871"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \"product_label\", \"source\", COUNT(*) AS review_count\n",
    "FROM combined_data\n",
    "GROUP BY \"product_label\", \"source\"\n",
    "ORDER BY review_count DESC;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, con=pg_engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9449af-b492-4066-b08a-4fae4c37b499",
   "metadata": {},
   "source": [
    "# Set up the embedding and FAISS step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52b8e25a-ccd1-46de-9d2f-731494127394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923e149313194fb4a525cdcd2506b774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02924e976bb446c1846e551e04c1ac70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e267b8562f3a42f48489a5bd0b6a453e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd1b0e8c0244cc0b1b5b684999be59d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a56aac4faed406c8bf8061ebc67cc0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd867420bcd4197b2ad620818b36d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa36c1abf704a0d82c83782343430b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d759514c0fd54f68b562ff209ab9f094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1827369784e643868f46f9072c0a0895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a5ea8efdd845ccac70abeaa06b9db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dadc7a146cb4fccb82811ceba55ad99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"combined_clean.csv\")\n",
    "df = df.dropna(subset=['content'])\n",
    "\n",
    "# Embed content\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "texts = df['content'].tolist()\n",
    "embeddings = model.encode(texts, convert_to_numpy=True)\n",
    "\n",
    "# Build FAISS index\n",
    "dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(embeddings)\n",
    "\n",
    "# Save index and metadata\n",
    "faiss.write_index(index, \"cybertruck_faiss.index\")\n",
    "df[['product_label', 'content', 'created_date', 'source']].to_csv(\"cybertruck_metadata.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1675e40e-6bab-41fc-b25c-8b0a3a77d167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                content   source created_date\n",
      "4396  The Cybertruck's design is bold and futuristic...  YouTube   2025-03-07\n",
      "4229  Love the Cybertruck's bold design, but curious...  YouTube   2025-03-07\n",
      "4228  Love the Cybertruck's bold design, but curious...  YouTube   2025-03-11\n",
      "4412  The cybertruck feels like it wouldve made a be...  YouTube   2025-03-26\n",
      "6141  Cybertruck is done, might as well scrap the de...   reddit   2021-05-20\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load index and metadata\n",
    "index = faiss.read_index(\"cybertruck_faiss.index\")\n",
    "metadata = pd.read_csv(\"cybertruck_metadata.csv\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def search(query, top_k=5):\n",
    "    query_vector = model.encode([query])\n",
    "    D, I = index.search(query_vector, top_k)\n",
    "    results = metadata.iloc[I[0]]\n",
    "    return results\n",
    "\n",
    "# Example use\n",
    "query = \"What do users say about Cybertruck design?\"\n",
    "results = search(query)\n",
    "print(results[['content', 'source', 'created_date']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3271907-48e8-45dc-a5b5-bc2dcb37f417",
   "metadata": {},
   "source": [
    "# RAG using Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "87e85123-d66a-4f51-abe2-8bd21563002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import faiss\n",
    "\n",
    "# Load your model and FAISS index\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "index = faiss.read_index(\"cybertruck_faiss.index\")\n",
    "metadata = pd.read_csv(\"cybertruck_metadata.csv\")\n",
    "\n",
    "# Configure Gemini\n",
    "genai.configure(api_key=\"AIzaSyAcdL28C5c2havVkOOTMusG8Cyxf-DEXzU\")\n",
    "gemini_model = genai.GenerativeModel(\"models/gemini-1.5-flash-latest\")\n",
    "\n",
    "# Function to search + generate\n",
    "def answer_with_gemini(query, top_k=5):\n",
    "    # Embed the query\n",
    "    query_vec = model.encode([query])\n",
    "    D, I = index.search(query_vec, top_k)\n",
    "\n",
    "    # Retrieve the top_k most relevant comments\n",
    "    results = metadata.iloc[I[0]]\n",
    "    context = \"\\n\".join(f\"- {row['content']}\" for _, row in results.iterrows())\n",
    "\n",
    "    # Construct prompt\n",
    "    prompt = f\"\"\"\n",
    "    You are a customer sentiment analyst using comments from Reddit and YouTube.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {query}\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate answer using Gemini\n",
    "    response = gemini_model.generate_content(prompt)\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "edbf2dfb-e90b-485a-98f1-15c8439bf6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment regarding the Cybertruck's price is mixed and largely depends on the context of its current price relative to competitors.\n",
      "\n",
      "**Negative Sentiment:**  A significant portion of the comments express concern that the *new* price point, coupled with the emergence of competing vehicles, makes the Cybertruck a poor value proposition.  There's a feeling it will \"bomb\" at the current pricing because alternatives now exist at a similar price.  One commenter even states they wouldn't buy it regardless of price due to its aesthetics.\n",
      "\n",
      "**Positive Sentiment:** Some remain optimistic, hoping the price stays the same (presumably the *original* price) and that its success would disrupt the truck market.  This suggests a belief that the original pricing was competitive and desirable.\n",
      "\n",
      "**Neutral/Uncertain Sentiment:**  One comment highlights a lack of understanding of the Cybertruck's value compared to competitors, requesting a side-by-side comparison, indicating uncertainty about its current pricing competitiveness.\n",
      "\n",
      "In summary, while some remain hopeful about the Cybertruck's original pricing strategy, the prevailing sentiment concerning the *current* price is largely negative. The appearance of competitive alternatives has significantly shifted opinions, making the current price a major point of concern for potential buyers.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer = answer_with_gemini(\"What do people think about the Cybertruck's price?\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d223529b-24b5-4f87-9e13-50d7bb7236d3",
   "metadata": {},
   "source": [
    "# MCP Sentiment Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e6b76253-1594-45dd-a259-f3bdf9d67474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing Cybertruck with Rivian R1T ===\n",
      "The data highlights a critical marketing and product strategy gap for the Cybertruck. While the high volume of polarized feedback might seem negative, it actually presents an opportunity. The R1T's lack of engagement indicates a potential problem with its market penetration and brand awareness.  Here's a multi-pronged strategy to address the Cybertruck's issues and capitalize on the R1T's relative silence:\n",
      "\n",
      "**I. Addressing Cybertruck Concerns:**\n",
      "\n",
      "* **Design Refinements (Mitigate Polarization):**  The data clearly shows design is a major point of contention.  While maintaining the iconic Cybertruck aesthetic, we should explore subtle design modifications to soften the harsh edges and increase perceived practicality. This could involve minor adjustments to proportions, integrating more traditional design cues subtly, or exploring different trim and color options to broaden appeal.\n",
      "\n",
      "* **Build Quality Assurance & Transparency:**  The perceived build quality concerns are damaging. Proactively address this by:\n",
      "    * **Enhanced Pre-Production Testing:** Implement rigorous and transparent testing protocols, sharing results with the public to build confidence.\n",
      "    * **Improved Manufacturing Processes:** Invest in advanced manufacturing techniques to minimize defects and improve consistency.\n",
      "    * **Clear Communication:** Publicly address any existing build quality issues, outlining corrective actions and emphasizing ongoing improvements.  Transparency builds trust.\n",
      "\n",
      "* **Value Proposition Enhancement:** The high price point is a concern.  We need to better articulate the Cybertruck's value proposition. This involves:\n",
      "    * **Highlighting Unique Selling Points (USPs):**  Emphasize its unique capabilities â€“ extreme durability, off-road prowess, futuristic technology, etc. â€“ and position it as a premium, high-performance vehicle, not just an electric truck.\n",
      "    * **Explore Pricing Tiers:** Consider introducing different trim levels to offer a wider range of price points and features, addressing the affordability concerns of some potential customers.\n",
      "    * **Showcase the \"Tesla Ecosystem\":**  Emphasize the integration with the Tesla Supercharger network, Autopilot, and other ecosystem benefits.\n",
      "\n",
      "**II. Capitalizing on Rivian's Low Engagement:**\n",
      "\n",
      "* **Comparative Marketing (Cautious Approach):**  While the R1T data is limited, it's an opportunity to highlight the Cybertruck's unique selling points *without* directly attacking the Rivian.  Focus on showcasing Cybertruck's superior features (e.g., range, towing capacity, innovative design) within its own marketing materials.\n",
      "\n",
      "* **Market Research & Focus Groups:**  Conduct thorough market research to understand what aspects of the R1T resonate (or don't) with consumers. This will inform the Cybertruck's messaging and further refine its features and value proposition.\n",
      "\n",
      "\n",
      "**III. Overall Strategy:**\n",
      "\n",
      "* **Targeted Marketing Campaigns:**  Create marketing campaigns that address the specific concerns identified in the data, highlighting the improvements made in design, build quality, and value.  Use testimonials and user-generated content (carefully curated) to show real-world examples of Cybertruck's capabilities and reliability.\n",
      "* **Community Engagement:** Foster a strong online community around the Cybertruck. This will create a space for open communication, address concerns proactively, and foster brand loyalty.\n",
      "* **Data-Driven Decision Making:**  Continuously monitor customer sentiment across all platforms.  Use this data to inform future product development and marketing strategies.\n",
      "\n",
      "\n",
      "By proactively addressing the criticisms and capitalizing on the relative lack of engagement surrounding the Rivian R1T, Tesla can shift the narrative around the Cybertruck and increase its market appeal. The key is to listen to customer feedback, demonstrate a commitment to improvement, and clearly communicate the Cybertruck's unique value proposition.\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "=== Comparing Cybertruck with Ford F-150 Lightning ===\n",
      "## Tesla Cybertruck: Strategies Based on Public Sentiment Analysis\n",
      "\n",
      "The analysis reveals a critical opportunity: the intense engagement with the Cybertruck, even if negative, represents a high level of brand awareness and anticipation.  While the polarization is a challenge, it's also a source of potential leverage.  We need to shift the conversation from contentious debate to informed acceptance, focusing on key areas:\n",
      "\n",
      "**I. Address the Polarizing Design:**\n",
      "\n",
      "* **Targeted Marketing Campaigns:**  Develop campaigns showcasing the *functionality* behind the unconventional design.  Highlight the ruggedness, aerodynamics (and resulting efficiency), and unique storage solutions.  Use videos and interactive experiences to demonstrate its capabilities, not just its aesthetics.  Focus on specific user groups (farmers, adventurers, etc.) whose needs align perfectly with the truck's functionality.\n",
      "* **Iterative Design Refinements (if feasible):**  While maintaining the core Cybertruck identity, subtle design adjustments could address some of the most frequently criticized aspects (e.g., wiper solution, side-mirror design, potential for improved interior ergonomics).  Transparency about these refinements and their purpose would be key.\n",
      "* **Community Engagement:**  Create online platforms dedicated to Cybertruck enthusiasts.  Foster a sense of community and ownership, encouraging feedback and collaboration on design-related questions. This allows for direct engagement with potential customers and the mitigation of negative perceptions.\n",
      "\n",
      "**II.  Improve Transparency and Manage Expectations:**\n",
      "\n",
      "* **Pre-Production Demonstrations:**  Amplify demonstrable proof points of performance, safety, and durability through controlled pre-production demonstrations focused on key selling points.  Invite influential reviewers and potential customers to experience the truck firsthand.\n",
      "* **Detailed Specifications and Pricing Breakdown:**  Provide clear and detailed explanations justifying the pricing.  Highlight the advanced technology, materials, and manufacturing processes contributing to the cost.  Break down the features and benefits to better justify the premium price point.\n",
      "* **Address Build Quality Concerns Proactively:**  Communicate transparently about the production process and quality control measures. Acknowledge potential challenges and demonstrate a commitment to addressing them effectively.\n",
      "\n",
      "**III.  Focus on Performance and User Experience:**\n",
      "\n",
      "* **Performance-Focused Marketing:**  Shift the narrative from design-centric discussions to performance-based ones.  Develop compelling content showcasing the towing capacity, off-road capabilities, acceleration, and range.  Release independent test results from reputable sources.\n",
      "* **User-Generated Content Campaign:**  Incentivize early adopters (pre-order holders) to share their experiences â€“ driving impressions, towing experiences, etc. â€“ on social media and other platforms.  This creates authentic and positive user feedback, countering negative narratives.\n",
      "\n",
      "**IV.  Learn from the F-150 Lightning's \"Success\":**\n",
      "\n",
      "The F-150's lighthearted anecdote highlights a potential marketing strategy: focus on clever, innovative features and highlight them with engaging, non-confrontational marketing.  While the Cybertruck shouldn't abandon its bold identity, it can incorporate the F-150's less-polarized approach in specific marketing campaigns.\n",
      "\n",
      "**V.  Continuous Monitoring of Public Sentiment:**\n",
      "\n",
      "Establish robust social listening mechanisms to monitor online conversations about the Cybertruck.  This enables real-time feedback analysis and allows for rapid adjustments to communication and marketing strategies.\n",
      "\n",
      "\n",
      "By addressing these areas, Tesla can transform the Cybertruckâ€™s polarized image into a more positive and widely accepted narrative, focusing on its unique capabilities and value proposition.  The goal is not to appease all critics, but to build a loyal following of informed and enthusiastic customers.\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "=== Comparing Cybertruck with Chevy Silverado EV ===\n",
      "## Tesla Cybertruck: Product Strategy Recommendations\n",
      "\n",
      "The analysis highlights a critical gap: the Cybertruck generates *lots* of noise, but little *useful* data.  The Silverado EV, conversely, is shrouded in silence, leaving its potential strengths and weaknesses largely unknown. This presents both challenges and opportunities for Tesla.\n",
      "\n",
      "**Addressing the Cybertruck's Issues:**\n",
      "\n",
      "1. **Mitigate Design Polarization:** While the unique design is a key selling point for some, it's a major deterrent for others.  We need to:\n",
      "    * **Targeted Marketing:** Develop separate marketing campaigns catering to distinct customer segments. One campaign highlighting the futuristic, disruptive aspects for tech-savvy buyers, and another showcasing its functionality and practicality for a more mainstream audience.  Focus less on the \"shock value\" and more on demonstrable benefits.\n",
      "    * **Design Refinements (subtle):**  While preserving the core design language, explore minor adjustments to address specific criticisms. This might involve improved panel integration or subtle styling changes to soften the sharp edges without losing the signature look.  User feedback, even negative, should be rigorously analyzed for actionable insights.\n",
      "\n",
      "2. **Address Build Quality Concerns:** The \"jettisoning panels\" issue is a serious reputational risk.\n",
      "    * **Transparency and Proactive Communication:** Publicly address the concerns, outlining the steps taken to improve manufacturing processes and ensure long-term durability.  Show, don't tell â€“ release detailed videos and documentation demonstrating improvements.\n",
      "    * **Pre-production Demonstrations:** Host targeted events for journalists and influencers showcasing the improved build quality and durability through rigorous testing.\n",
      "\n",
      "3. **Improve Price Perception:** The high price point is a significant barrier.\n",
      "    * **Value Proposition Clarity:**  Clearly articulate the Cybertruck's value proposition beyond its unique design. Highlight the superior performance, longevity, and technological advantages compared to traditional trucks â€“ supported by data and independent reviews.\n",
      "    * **Flexible Financing Options:** Offer a wider range of financing options to make the purchase more accessible.\n",
      "\n",
      "4. **Gather User Data:**  The lack of comprehensive user reviews is a major weakness.\n",
      "    * **Beta Program Expansion:**  Expand the early access/beta program to a broader range of users, collecting detailed feedback on performance, usability, and features.  This data should be used to iteratively improve the vehicle.\n",
      "    * **Incentivized Reviews:**  Encourage genuine reviews through incentives (not just paid endorsements), ensuring a balance of positive and negative feedback.  This data should be publicly available and transparently managed.\n",
      "\n",
      "\n",
      "**Leveraging the Silverado EV's Silence:**\n",
      "\n",
      "The lack of feedback on the Silverado EV is a double-edged sword.  It presents an opportunity to highlight the Cybertruck's superior technology and features in a more strategic way, focusing on specific differentiators instead of general comparisons.\n",
      "\n",
      "\n",
      "**Overall Strategy:**\n",
      "\n",
      "The Cybertruck's current marketing strategy needs a significant overhaul.  Shifting the focus from generating buzz to gathering concrete, actionable data and addressing legitimate concerns is crucial for its success.  This data-driven approach, combined with targeted marketing and design refinements, can transform public perception and build confidence in the Cybertruck's potential. The Silverado EV's absence of feedback should be viewed as an opportunity for highlighting unique selling points, rather than relying on indirect comparisons.\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "=== Comparing Cybertruck with GMC Hummer EV ===\n",
      "## Tesla Cybertruck: Strategic Improvements & Mitigation Strategies\n",
      "\n",
      "The comparison highlights key areas where the Cybertruck's negative sentiment surpasses the Hummer EV's, primarily due to a confluence of design, perceived build quality, and marketing issues. To improve the Cybertruck's market reception and address the \"lack of value\" perception, Tesla needs a multi-pronged strategy:\n",
      "\n",
      "**1. Address Build Quality Concerns & Transparency:**\n",
      "\n",
      "* **Proactive Communication:**  Tesla needs to proactively address the \"jettisoning exterior panels\" concerns with transparent communication about the engineering choices, rigorous testing procedures, and any improvements made to address these issues.  Release detailed engineering specifications and videos showcasing durability tests.\n",
      "* **Improved Quality Control:**  Invest heavily in improving manufacturing processes to ensure consistent build quality and eliminate any perceived weaknesses.  A robust quality control system is paramount to rebuild consumer trust.\n",
      "* **Early Access Program with Feedback Loop:** A carefully selected early access program with a commitment to incorporating feedback from users regarding build quality and functionality can significantly improve the final product and demonstrate responsiveness.\n",
      "\n",
      "**2. Reimagine Marketing & Pricing Strategy:**\n",
      "\n",
      "* **Soften the Tone:**  The \"buy my car or else\" attitude needs to be completely abandoned.  Marketing should shift towards highlighting the Cybertruck's unique capabilities and benefits rather than relying on a confrontational approach. Focus on its innovative aspects and functionality.\n",
      "* **Tiered Pricing & Features:**  Consider introducing a tiered pricing strategy with different trim levels offering varying features and capabilities.  This allows for more accessibility and addresses the \"exorbitant cost\" criticism.  Focus on value-added features for each tier.\n",
      "* **Highlight Practicality:**  Marketing should shift to demonstrate the Cybertruck's practicality for different use cases beyond its edgy design. This includes showcasing its versatility, cargo capacity, and towing capabilities in real-world scenarios.\n",
      "\n",
      "**3. Design Refinement (without compromising the core vision):**\n",
      "\n",
      "* **Address Sharp Edges (Subtly):** While preserving the core futuristic design, consider subtle refinements to address concerns about the sharp edges, potentially impacting usability or safety. This might involve slightly rounded corners or protective features.\n",
      "* **Improved Interior Design and Materials:**  The interior design should emphasize practicality and comfort, potentially offering customizable options to improve the perceived value.  Explore different material choices to elevate the interior's perceived quality.\n",
      "\n",
      "**4. Focus on Value Proposition:**\n",
      "\n",
      "* **Showcase Unique Capabilities:**  The Cybertruck's unique selling points, such as its exceptional towing capacity, off-road capabilities, and stainless steel construction, need to be effectively communicated and demonstrated.  Focus on highlighting the *value* these unique features offer.\n",
      "* **Comparative Analysis:**  Marketing materials should directly address the price point by comparing its capabilities and features to similar vehicles (even within the high-end market), emphasizing its superior value in specific areas.\n",
      "\n",
      "**In Summary:** The Cybertruck's issues are not insurmountable. By focusing on improving build quality, refining its marketing strategy, and addressing design concerns with a user-centric approach, Tesla can transform the perception of the Cybertruck from a polarizing novelty to a desirable and value-driven vehicle.  The core vision of a futuristic truck can be maintained while addressing the significant public concerns surrounding it.\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Configure Gemini\n",
    "GENAI_API_KEY = \"AIzaSyAcdL28C5c2havVkOOTMusG8Cyxf-DEXzU\"\n",
    "genai.configure(api_key=GENAI_API_KEY)\n",
    "gemini = genai.GenerativeModel(\"models/gemini-1.5-flash-latest\")\n",
    "\n",
    "# Load embedding model, FAISS index, and metadata\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "index = faiss.read_index(\"cybertruck_faiss.index\")\n",
    "metadata = pd.read_csv(\"cybertruck_metadata.csv\")\n",
    "\n",
    "def retrieve_comments(product, top_k=5):\n",
    "    \"\"\"Retrieves top_k comments for a given product using FAISS.\"\"\"\n",
    "    comments = metadata[metadata['product_label'].str.lower() == product.lower()]['content'].tolist()\n",
    "    if not comments:\n",
    "        return \"No comments found for this product.\"\n",
    "    vectors = embedding_model.encode(comments, convert_to_numpy=True)\n",
    "    index_local = faiss.IndexFlatL2(vectors.shape[1])\n",
    "    index_local.add(vectors)\n",
    "    D, I = index_local.search(vectors[:1], top_k)\n",
    "    selected = [comments[i] for i in I[0]]\n",
    "    return \"\\n\".join(f\"- {c}\" for c in selected)\n",
    "\n",
    "def cybertruck_analyst(comments):\n",
    "    prompt = f\"\"\"\n",
    "    You are a sentiment analyst.\n",
    "    Summarize what users say about the Tesla Cybertruck based on the following comments:\n",
    "\n",
    "    {comments}\n",
    "\n",
    "    Focus on design, build quality, and performance.\n",
    "    \"\"\"\n",
    "    return gemini.generate_content(prompt).text\n",
    "\n",
    "def competitor_analyst(product, comments):\n",
    "    prompt = f\"\"\"\n",
    "    You are a sentiment analyst.\n",
    "    Summarize what users say about the {product} based on the following comments:\n",
    "\n",
    "    {comments}\n",
    "\n",
    "    Focus on design, build quality, and performance.\n",
    "    \"\"\"\n",
    "    return gemini.generate_content(prompt).text\n",
    "\n",
    "def comparator(cyber_summary, rival_summary):\n",
    "    prompt = f\"\"\"\n",
    "    Compare public sentiment between the Tesla Cybertruck and its competitor.\n",
    "\n",
    "    Cybertruck Summary:\n",
    "    {cyber_summary}\n",
    "\n",
    "    Competitor Summary:\n",
    "    {rival_summary}\n",
    "\n",
    "    Focus on differences and similarities in user opinions.\n",
    "    \"\"\"\n",
    "    return gemini.generate_content(prompt).text\n",
    "\n",
    "def strategist(comparison_text):\n",
    "    prompt = f\"\"\"\n",
    "    You are a Tesla product strategist.\n",
    "    Based on the following comparison, suggest improvements or strategies for the Cybertruck:\n",
    "\n",
    "    {comparison_text}\n",
    "    \"\"\"\n",
    "    return gemini.generate_content(prompt).text\n",
    "\n",
    "# Example end-to-end for all competitors\n",
    "if __name__ == \"__main__\":\n",
    "    competitors = [\"Rivian R1T\", \"Ford F-150 Lightning\", \"Chevy Silverado EV\", \"GMC Hummer EV\"]\n",
    "    cyber_comments = retrieve_comments(\"Tesla Cybertruck\")\n",
    "    cyber_summary = cybertruck_analyst(cyber_comments)\n",
    "\n",
    "    for rival in competitors:\n",
    "        print(f\"\\n=== Comparing Cybertruck with {rival} ===\")\n",
    "        rival_comments = retrieve_comments(rival)\n",
    "        rival_summary = competitor_analyst(rival, rival_comments)\n",
    "        comparison = comparator(cyber_summary, rival_summary)\n",
    "        recommendation = strategist(comparison)\n",
    "\n",
    "        print(recommendation)\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8853f9-74c1-496b-83dc-72b6cfa187f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
